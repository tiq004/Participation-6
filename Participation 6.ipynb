{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"C:/Users/j3543/Desktop/DSC180A-B05-Project-main/data/raw/\"\n",
    "out_path = \"C:/Users/j3543/Desktop/DSC180A-B05-Project-main/data/out/result.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def cal_attributes(entries, raw_path,out_path):\n",
    "    # I extracted the features based on the columns below.\n",
    "    cols = ['Time','1->2Bytes','2->1Bytes','1->2Pkts','2->1Pkts']\n",
    "    temp = pd.read_csv(raw_path + entries[0])[cols]\n",
    "    # I used the describe() function to find the attributes \n",
    "    #of each column, which includes mean, median, max min etc.\n",
    "    desc = temp.describe()\n",
    "    new_cols = {}\n",
    "    \n",
    "    # I used the for loop to make a dictionary with only keys of \n",
    "    #the generated features name from the function describe().\n",
    "    for col in desc.columns:\n",
    "        temp_col = {}\n",
    "        name = \"\"\n",
    "        for ind in desc.index:\n",
    "            name = str(col) + \"_\" + str(ind)\n",
    "            new_cols[name] = []\n",
    "            \n",
    "    # Adding more keys related to peaks to the dictionary \n",
    "    peak_col = ['1->2Bytes','2->1Bytes','1->2Pkts','2->1Pkts']\n",
    "    for i in peak_col:\n",
    "            name = str(i) + \"_\" + \"peak_num\"\n",
    "            new_cols[name] = []\n",
    "    \n",
    "    # I used the for loop to populate the dictionary created above \n",
    "    #with the data from describe() and find_peaks.\n",
    "    for i in entries:\n",
    "        p144 = pd.read_csv(raw_path + i)\n",
    "        temp = p144[cols]\n",
    "        \n",
    "        #Here I used the find_peak to count the number of spikes \n",
    "        #of each column except Time.\n",
    "        for i in peak_col:\n",
    "            peaks, _ = find_peaks(temp[i], height=0)\n",
    "            name = str(i) + \"_\" + \"peak_num\"\n",
    "            item = len(peaks)\n",
    "            new_cols[name] = new_cols[name] + [item]\n",
    "            \n",
    "        #This block of code is used to put the data generated by \n",
    "        #describe() into the dictionary.\n",
    "        desc = temp.describe()\n",
    "        for col in desc.columns:\n",
    "            temp_col = {}\n",
    "            name = \"\"\n",
    "            for ind in desc.index:\n",
    "                name = str(col) + \"_\" + str(ind)\n",
    "                item = desc[col][ind]\n",
    "                new_cols[name] = new_cols[name] + [item]\n",
    "    # The function returns a tabel of features for each file.\n",
    "    feats = pd.DataFrame.from_dict(new_cols)\n",
    "    feats.to_csv(out_path + \"cleaned_features.csv\", index = False, header=True)\n",
    "    return feats\n",
    "\n",
    "def cal_labels(entries,raw_path,out_path):\n",
    "    #This for loop is to convert the list of names of the files into a 2d \n",
    "    #lists called new_str.\n",
    "    #Each element in this list is a list of cleaned labels of the file.\n",
    "    new_str = []\n",
    "    for i in entries:\n",
    "        # The following process replace the wrong formating and wording \n",
    "        #into the correct format.\n",
    "        temp=i.replace('[','')\n",
    "        temp=temp.replace(']','')\n",
    "        temp=temp.replace(' ','')\n",
    "        temp=temp.replace('_','-')\n",
    "        for i in range(10):\n",
    "            string = \"-\"+str(i) + \".csv\"\n",
    "            temp=temp.replace(string,'')\n",
    "        temp=temp.replace('.csv','')\n",
    "        temp=temp.replace('nonvpn','novpn')\n",
    "        for num in range(10):\n",
    "            temp=temp.replace('('+str(num)+')','')\n",
    "        str_list=temp.split('-')\n",
    "        new_str.append(str_list)\n",
    "    labels = {'username','video/novideo','streaming_provider','quality','playback_speed','vpn/novpn','platform','clean/noisy','date'}\n",
    "\n",
    "    big_list = set(list(np.concatenate(new_str).flat))\n",
    "    #For each of the labels, I created a empty list which would be \n",
    "    #populated later using if statements.\n",
    "    username = [i[0] for i in new_str]\n",
    "    video = []\n",
    "    streaming_provider = []\n",
    "    quality = []\n",
    "    playback_speed = []\n",
    "    vpn = []\n",
    "    platform = []\n",
    "    clean = []\n",
    "    date = [i[-1][:8] for i in new_str]\n",
    "    \n",
    "    #This for look check every entries of new_str(the cleaned list of \n",
    "    #file names) and populate each of labels' array one by one.\n",
    "    for i in new_str:\n",
    "        #For example, if \"nonvpn\" is in this entry, then the \"nonvpn\"\n",
    "        #would be appended to the vpn/novpn list.\n",
    "        if \"novpn\" in i:\n",
    "            vpn.append(\"novpn\")\n",
    "        else:\n",
    "            vpn.append(\"vpn\")\n",
    "        #The following if statements have the same logic as the above\n",
    "        #if statement.\n",
    "        if \"novideo\" in i:\n",
    "            video.append(\"novideo\")\n",
    "        else:\n",
    "            video.append(\"video\")\n",
    "        \n",
    "        if \"youtube\" in i:\n",
    "            streaming_provider.append(\"youtube\")\n",
    "        elif \"hulu\" in i:\n",
    "            streaming_provider.append(\"hulu\")\n",
    "        elif \"amazon\" in i:\n",
    "            streaming_provider.append(\"amazonprime\")\n",
    "        elif \"netflix\" in i:\n",
    "            streaming_provider.append(\"netflix\")\n",
    "        elif \"bilibili\" in i:\n",
    "            streaming_provider.append(\"bilibili\")\n",
    "        else:\n",
    "            streaming_provider.append(\"NA\")\n",
    "\n",
    "        if \"clean\" in i:\n",
    "            clean.append(\"clean\")\n",
    "        elif \"noisy\" in i:\n",
    "            clean.append(\"noisy\")\n",
    "        else:\n",
    "            clean.append(\"NA\")\n",
    "\n",
    "        counter = 0\n",
    "        for j in i:\n",
    "            if counter == len(i)-1:\n",
    "                quality.append(\"NA\")\n",
    "                break\n",
    "            if \"1080\" in j:\n",
    "                quality.append(\"1080p\")\n",
    "                break\n",
    "            elif \"2160\" in j:\n",
    "                quality.append(\"2160p\")\n",
    "                break\n",
    "            elif \"240\" in j:\n",
    "                quality.append(\"240p\")\n",
    "                break\n",
    "            elif \"480\" in j:\n",
    "                quality.append(\"480p\")\n",
    "                break\n",
    "            elif \"144\" in j:\n",
    "                quality.append(\"144p\")\n",
    "                break\n",
    "            elif \"320\" in j:\n",
    "                quality.append(\"320p\")\n",
    "                break\n",
    "            elif \"720\" in j:\n",
    "                quality.append(\"720p\")\n",
    "                break\n",
    "            counter = counter + 1\n",
    "\n",
    "        if \"windows\" in i:\n",
    "            platform.append(\"windows\")\n",
    "        elif \"mac\" in i:\n",
    "            platform.append(\"mac\")\n",
    "        elif \"linux\" in i:\n",
    "            platform.append(\"linux\")\n",
    "        else:\n",
    "            platform.append(\"NA\")\n",
    "\n",
    "        if (\"1x\" or \"1\") in i:\n",
    "            playback_speed.append(\"1x\")\n",
    "        elif (\"2x\" or \"2\" or \"2.0x\") in i:\n",
    "            playback_speed.append(\"2x\")\n",
    "        elif (\"1.5x\" or \"1.5x\" or \"1.5x\") in i:\n",
    "            playback_speed.append(\"1.5x\")\n",
    "        elif (\"1.4x\" or \"1.4\"or \"1.40x\") in i:\n",
    "            playback_speed.append(\"1.4x\")\n",
    "        elif (\"0.5x\" or \"0.5\") in i:\n",
    "            playback_speed.append(\"0.5x\")\n",
    "        elif (\"0.25x\" or \"0.25\") in i:\n",
    "            playback_speed.append(\"0.25x\")\n",
    "        elif (\"1.25x\" or \"1.25\") in i:\n",
    "            playback_speed.append(\"1.25x\")\n",
    "        elif (\"1.75x\" or \"1.75\") in i:\n",
    "            playback_speed.append(\"1.75x\")\n",
    "        else:\n",
    "            playback_speed.append(\"NA\")\n",
    "    \n",
    "    # Finally, we creat a dictionary of each label corresponding \n",
    "    #to tehir lists for all files \n",
    "    # and then convert this dictionary to table as the resturned result.\n",
    "    labels = {'username':username,'video/novideo':video,'streaming_provider':streaming_provider,'quality':quality,'playback_speed':playback_speed,'vpn/novpn':vpn,'platform':platform,'clean/noisy':clean,'date':date}\n",
    "    label_table = pd.DataFrame.from_dict(labels)\n",
    "    label_table.to_csv(out_path + 'cleaned_labels.csv', index = False, header=True)\n",
    "    return label_table\n",
    "\n",
    "def combine_output(entries,raw_path, out_path):\n",
    "    df1 = cal_attributes(entries,raw_path, out_path)\n",
    "    df2 = cal_labels(entries,raw_path, out_path)\n",
    "    horizontal_stack = pd.concat([df2, df1], axis=1)\n",
    "    horizontal_stack.to_csv(out_path + \"combined_result.csv\", index = False, header=True)\n",
    "    return horizontal_stack\n",
    "\n",
    "def original_out(raw_path,out_path):\n",
    "    new1 = []\n",
    "    new2 = []\n",
    "    new3 = []\n",
    "    new4 = []\n",
    "    entries = os.listdir(raw_path)\n",
    "    #entries.remove('.git')\n",
    "    cal_labels(entries,raw_path,out_path).to_csv(out_path+\"original_out.csv\", index = False, header=True)\n",
    "    return entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = original_out(raw_path,out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  combine_output(ok,raw_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"cleaned_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"cleaned_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>video/novideo</th>\n",
       "      <th>streaming_provider</th>\n",
       "      <th>quality</th>\n",
       "      <th>playback_speed</th>\n",
       "      <th>vpn/novpn</th>\n",
       "      <th>platform</th>\n",
       "      <th>clean/noisy</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>arv020</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480p</td>\n",
       "      <td>1x</td>\n",
       "      <td>vpn</td>\n",
       "      <td>mac</td>\n",
       "      <td>clean</td>\n",
       "      <td>20201101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>imnemato</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1080p</td>\n",
       "      <td>1x</td>\n",
       "      <td>vpn</td>\n",
       "      <td>mac</td>\n",
       "      <td>clean</td>\n",
       "      <td>20201031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>stdoan</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vpn</td>\n",
       "      <td>windows</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20201029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>jeq004</td>\n",
       "      <td>1</td>\n",
       "      <td>netflix</td>\n",
       "      <td>1080p</td>\n",
       "      <td>1x</td>\n",
       "      <td>vpn</td>\n",
       "      <td>mac</td>\n",
       "      <td>clean</td>\n",
       "      <td>20201101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>imnemato</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1080p</td>\n",
       "      <td>1x</td>\n",
       "      <td>vpn</td>\n",
       "      <td>mac</td>\n",
       "      <td>clean</td>\n",
       "      <td>20201031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>chy238</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1x</td>\n",
       "      <td>vpn</td>\n",
       "      <td>windows</td>\n",
       "      <td>clean</td>\n",
       "      <td>20201103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>zij034</td>\n",
       "      <td>1</td>\n",
       "      <td>youtube</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1x</td>\n",
       "      <td>vpn</td>\n",
       "      <td>windows</td>\n",
       "      <td>clean</td>\n",
       "      <td>20201101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>pgaddiso</td>\n",
       "      <td>1</td>\n",
       "      <td>youtube</td>\n",
       "      <td>720p</td>\n",
       "      <td>1x</td>\n",
       "      <td>vpn</td>\n",
       "      <td>linux</td>\n",
       "      <td>clean</td>\n",
       "      <td>20201102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>dyaseen</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>novpn</td>\n",
       "      <td>windows</td>\n",
       "      <td>clean</td>\n",
       "      <td>20201102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>stdoan</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144p</td>\n",
       "      <td>1x</td>\n",
       "      <td>vpn</td>\n",
       "      <td>windows</td>\n",
       "      <td>clean</td>\n",
       "      <td>20201102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     username  video/novideo streaming_provider quality playback_speed  \\\n",
       "0      arv020              1                NaN    480p             1x   \n",
       "1    imnemato              1                NaN   1080p             1x   \n",
       "2      stdoan              0                NaN     NaN            NaN   \n",
       "3      jeq004              1            netflix   1080p             1x   \n",
       "4    imnemato              1                NaN   1080p             1x   \n",
       "..        ...            ...                ...     ...            ...   \n",
       "174    chy238              1                NaN     NaN             1x   \n",
       "175    zij034              1            youtube     NaN             1x   \n",
       "176  pgaddiso              1            youtube    720p             1x   \n",
       "177   dyaseen              1                NaN     NaN            NaN   \n",
       "178    stdoan              1                NaN    144p             1x   \n",
       "\n",
       "    vpn/novpn platform clean/noisy      date  \n",
       "0         vpn      mac       clean  20201101  \n",
       "1         vpn      mac       clean  20201031  \n",
       "2         vpn  windows         NaN  20201029  \n",
       "3         vpn      mac       clean  20201101  \n",
       "4         vpn      mac       clean  20201031  \n",
       "..        ...      ...         ...       ...  \n",
       "174       vpn  windows       clean  20201103  \n",
       "175       vpn  windows       clean  20201101  \n",
       "176       vpn    linux       clean  20201102  \n",
       "177     novpn  windows       clean  20201102  \n",
       "178       vpn  windows       clean  20201102  \n",
       "\n",
       "[179 rows x 9 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-&gt;2Bytes_count</th>\n",
       "      <th>1-&gt;2Bytes_mean</th>\n",
       "      <th>1-&gt;2Bytes_std</th>\n",
       "      <th>1-&gt;2Bytes_min</th>\n",
       "      <th>1-&gt;2Bytes_25%</th>\n",
       "      <th>1-&gt;2Bytes_50%</th>\n",
       "      <th>1-&gt;2Bytes_75%</th>\n",
       "      <th>1-&gt;2Bytes_max</th>\n",
       "      <th>2-&gt;1Bytes_count</th>\n",
       "      <th>2-&gt;1Bytes_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>2-&gt;1Pkts_mean</th>\n",
       "      <th>2-&gt;1Pkts_std</th>\n",
       "      <th>2-&gt;1Pkts_min</th>\n",
       "      <th>2-&gt;1Pkts_25%</th>\n",
       "      <th>2-&gt;1Pkts_50%</th>\n",
       "      <th>2-&gt;1Pkts_75%</th>\n",
       "      <th>2-&gt;1Pkts_max</th>\n",
       "      <th>1-&gt;2Bytes_peak_num</th>\n",
       "      <th>2-&gt;1Bytes_peak_num</th>\n",
       "      <th>1-&gt;2Pkts_peak_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39823.0</td>\n",
       "      <td>522.630917</td>\n",
       "      <td>869.631139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.00</td>\n",
       "      <td>324.0</td>\n",
       "      <td>454.00</td>\n",
       "      <td>20837.0</td>\n",
       "      <td>39823.0</td>\n",
       "      <td>674.446300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542651</td>\n",
       "      <td>12.884026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>833.0</td>\n",
       "      <td>11793</td>\n",
       "      <td>998</td>\n",
       "      <td>4428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>208.0</td>\n",
       "      <td>10252.245192</td>\n",
       "      <td>25378.133865</td>\n",
       "      <td>32.0</td>\n",
       "      <td>217.00</td>\n",
       "      <td>436.0</td>\n",
       "      <td>15233.75</td>\n",
       "      <td>197377.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>438950.370192</td>\n",
       "      <td>...</td>\n",
       "      <td>327.764423</td>\n",
       "      <td>508.281720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>752.25</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>72</td>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>1753.118563</td>\n",
       "      <td>4826.919546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1584.50</td>\n",
       "      <td>83230.0</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>40290.303593</td>\n",
       "      <td>...</td>\n",
       "      <td>30.295808</td>\n",
       "      <td>131.456713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2131.0</td>\n",
       "      <td>464</td>\n",
       "      <td>463</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1613.297619</td>\n",
       "      <td>4322.107451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.25</td>\n",
       "      <td>291.0</td>\n",
       "      <td>667.50</td>\n",
       "      <td>26393.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>10502.976190</td>\n",
       "      <td>...</td>\n",
       "      <td>9.404762</td>\n",
       "      <td>65.349868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>596.0</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>225.0</td>\n",
       "      <td>11213.537778</td>\n",
       "      <td>26657.856416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262.00</td>\n",
       "      <td>434.0</td>\n",
       "      <td>11994.00</td>\n",
       "      <td>150232.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>344586.622222</td>\n",
       "      <td>...</td>\n",
       "      <td>257.297778</td>\n",
       "      <td>455.162388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>361.00</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>63</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>324.0</td>\n",
       "      <td>23491.459877</td>\n",
       "      <td>33257.810287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1884.75</td>\n",
       "      <td>9807.0</td>\n",
       "      <td>33746.25</td>\n",
       "      <td>239075.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>375604.037037</td>\n",
       "      <td>...</td>\n",
       "      <td>280.444444</td>\n",
       "      <td>397.938239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>111.5</td>\n",
       "      <td>450.75</td>\n",
       "      <td>3496.0</td>\n",
       "      <td>94</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>468.0</td>\n",
       "      <td>13646.286325</td>\n",
       "      <td>46535.150984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.75</td>\n",
       "      <td>424.0</td>\n",
       "      <td>1008.00</td>\n",
       "      <td>422098.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>159171.989316</td>\n",
       "      <td>...</td>\n",
       "      <td>120.788462</td>\n",
       "      <td>442.261819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5162.0</td>\n",
       "      <td>140</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>759.0</td>\n",
       "      <td>3038.623188</td>\n",
       "      <td>13049.231975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.00</td>\n",
       "      <td>160.0</td>\n",
       "      <td>385.00</td>\n",
       "      <td>118960.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>63256.405797</td>\n",
       "      <td>...</td>\n",
       "      <td>49.131752</td>\n",
       "      <td>255.463831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>245</td>\n",
       "      <td>179</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>3566.839343</td>\n",
       "      <td>7560.993421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1921.00</td>\n",
       "      <td>38700.0</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>145413.570972</td>\n",
       "      <td>...</td>\n",
       "      <td>97.552716</td>\n",
       "      <td>238.076533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>649</td>\n",
       "      <td>582</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>216.0</td>\n",
       "      <td>2476.944444</td>\n",
       "      <td>5706.709419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1300.75</td>\n",
       "      <td>32021.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>51189.370370</td>\n",
       "      <td>...</td>\n",
       "      <td>42.412037</td>\n",
       "      <td>111.727541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>668.0</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1->2Bytes_count  1->2Bytes_mean  1->2Bytes_std  1->2Bytes_min  \\\n",
       "0            39823.0      522.630917     869.631139            0.0   \n",
       "1              208.0    10252.245192   25378.133865           32.0   \n",
       "2             1670.0     1753.118563    4826.919546            0.0   \n",
       "3               84.0     1613.297619    4322.107451            0.0   \n",
       "4              225.0    11213.537778   26657.856416            0.0   \n",
       "..               ...             ...            ...            ...   \n",
       "174            324.0    23491.459877   33257.810287            0.0   \n",
       "175            468.0    13646.286325   46535.150984            0.0   \n",
       "176            759.0     3038.623188   13049.231975            0.0   \n",
       "177           2191.0     3566.839343    7560.993421            0.0   \n",
       "178            216.0     2476.944444    5706.709419            0.0   \n",
       "\n",
       "     1->2Bytes_25%  1->2Bytes_50%  1->2Bytes_75%  1->2Bytes_max  \\\n",
       "0           190.00          324.0         454.00        20837.0   \n",
       "1           217.00          436.0       15233.75       197377.0   \n",
       "2            61.00          152.0        1584.50        83230.0   \n",
       "3           224.25          291.0         667.50        26393.0   \n",
       "4           262.00          434.0       11994.00       150232.0   \n",
       "..             ...            ...            ...            ...   \n",
       "174        1884.75         9807.0       33746.25       239075.0   \n",
       "175         133.75          424.0        1008.00       422098.0   \n",
       "176         136.00          160.0         385.00       118960.0   \n",
       "177          72.00          190.0        1921.00        38700.0   \n",
       "178          61.00          120.0        1300.75        32021.0   \n",
       "\n",
       "     2->1Bytes_count  2->1Bytes_mean  ...  2->1Pkts_mean  2->1Pkts_std  \\\n",
       "0            39823.0      674.446300  ...       0.542651     12.884026   \n",
       "1              208.0   438950.370192  ...     327.764423    508.281720   \n",
       "2             1670.0    40290.303593  ...      30.295808    131.456713   \n",
       "3               84.0    10502.976190  ...       9.404762     65.349868   \n",
       "4              225.0   344586.622222  ...     257.297778    455.162388   \n",
       "..               ...             ...  ...            ...           ...   \n",
       "174            324.0   375604.037037  ...     280.444444    397.938239   \n",
       "175            468.0   159171.989316  ...     120.788462    442.261819   \n",
       "176            759.0    63256.405797  ...      49.131752    255.463831   \n",
       "177           2191.0   145413.570972  ...      97.552716    238.076533   \n",
       "178            216.0    51189.370370  ...      42.412037    111.727541   \n",
       "\n",
       "     2->1Pkts_min  2->1Pkts_25%  2->1Pkts_50%  2->1Pkts_75%  2->1Pkts_max  \\\n",
       "0             0.0           0.0           0.0          0.00         833.0   \n",
       "1             0.0           0.0           1.5        752.25        1680.0   \n",
       "2             0.0           1.0           1.0          7.00        2131.0   \n",
       "3             0.0           0.0           0.0          0.25         596.0   \n",
       "4             0.0           0.0           1.0        361.00        1596.0   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "174           0.0           5.0         111.5        450.75        3496.0   \n",
       "175           0.0           0.0           0.0          2.00        5162.0   \n",
       "176           0.0           0.0           0.0          1.00        1934.0   \n",
       "177           0.0           0.0           1.0          3.00        1151.0   \n",
       "178           0.0           1.0           1.0          7.00         668.0   \n",
       "\n",
       "     1->2Bytes_peak_num  2->1Bytes_peak_num  1->2Pkts_peak_num  \n",
       "0                 11793                 998               4428  \n",
       "1                    72                  64                 63  \n",
       "2                   464                 463                404  \n",
       "3                    21                  18                 15  \n",
       "4                    63                  56                 55  \n",
       "..                  ...                 ...                ...  \n",
       "174                  94                  98                 98  \n",
       "175                 140                 100                102  \n",
       "176                 245                 179                190  \n",
       "177                 649                 582                553  \n",
       "178                  54                  56                 48  \n",
       "\n",
       "[179 rows x 35 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features.iloc[:, 8:43]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.replace([\"video\", \"novideo\"], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j3543\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "# evaluate predictions\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9629629629629629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j3543\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model2.fit(X_train, y_train)\n",
    "y_pred2 = model1.predict(X_test)\n",
    "# evaluate predictions\n",
    "acc2 = accuracy_score(y_test, y_pred2)\n",
    "print('Accuracy: {}'.format(acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
